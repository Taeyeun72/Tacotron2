{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dc32fe5",
   "metadata": {},
   "source": [
    "# Tacotron2: Natural TTS Synthesis by Conditioning Wavenet on Mel Spectrogram Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e87899",
   "metadata": {},
   "source": [
    "- **Tacotron2**: **Tacotron** 구조와 **WaveNet** 구조를 활용하여 더 좋은 음성 합성 성능을 가지는 **TTS** 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee2f89d",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75eaf5e2",
   "metadata": {},
   "source": [
    "- **모델 전체 구조**\n",
    "<img src=\"01.png\" width=70% height=70%>\n",
    "\n",
    "    - Tacotron 모델과는 달리 CBHG Module과 GRU 대신 **Vanilla LSTM**과 **Convolutional Layers**를 사용해서 훨씬 단순한 모델이 되었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dcb7a2",
   "metadata": {},
   "source": [
    "## 1. Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873a0338",
   "metadata": {},
   "source": [
    "- **Encoder 전체 구조**\n",
    "<img src=\"02.png\" width=40% height=40%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3880ba95",
   "metadata": {},
   "source": [
    "## 2. Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642915db",
   "metadata": {},
   "source": [
    "- **Location-Sensitive Attention**: Tacotron에서 사용한 **Bahdanau (Additive) Attention**에서 연장하여 이전 time step의 Attention Weights를 현재 time step에서 활용하는 Attention 기법\n",
    "    - **Attention 전체 구조**\n",
    "    <img src=\"03.png\" width=70% height=70%>\n",
    "    \n",
    "    - 식은 다음과 같다.\n",
    "        1. Score: $\\text{Score}(\\mathbf{d}_{t}, \\mathbf{h}) = \\mathbf{W}^{T} \\tanh (\\mathbf{W_{d}}\\mathbf{d}_{t} + \\mathbf{W_{h}}\\mathbf{h} + \\mathbf{W_{f}}\\mathbf{f}_{t} + \\mathbf{b})$  \n",
    "        ($t-1$ step에서의 Attention Weight $\\mathbf{a}_{t-1}$와 가중치 행렬(filter) $\\mathbf{F}$에 대하여 $\\mathbf{f}_{t} = \\mathbf{F} * \\mathbf{a}_{t-1}$)\n",
    "            - Bahdanau Additive Attention의 Score는 다음과 같다. 위와 비교해보자.\n",
    "                - Score: $\\text{Score}(\\mathbf{d}_{t}, \\mathbf{h}) = \\mathbf{W}^{T} \\tanh (\\mathbf{W_{d}}\\mathbf{d}_{t}+\\mathbf{W_{h}}\\mathbf{h})$\n",
    "        2. Attention Weight: $a_{t, j} = \\frac{\\exp(\\text{Score}(\\mathbf{d}_{t}, {h}_{j}))}{\\sum_{i=1}^{n} \\exp(\\text{Score}(\\mathbf{d}_{t}, h_{i}))}$\n",
    "        3. Context: $\\mathbf{c}_{t} = \\sum_{j=1}^{n} a_{t, j} h_{j}$  \n",
    "        ($\\mathbf{d}_{t}$: $t$ step에서의 Query 벡터, $\\mathbf{h}$: Encoder의 output)\n",
    "    - Location-Sensitive Attention은 기존의 Additive Attention에서 <u>불필요한 반복되거나 필요한 부분이 무시되는 시퀀스가 발생하는 현상을 완화</u>시켜준다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb0a269",
   "metadata": {},
   "source": [
    "## 3. Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a780ae34",
   "metadata": {},
   "source": [
    "- **Decoder 전체 구조**\n",
    "<img src=\"04.png\" width=70% height=70%>\n",
    "\n",
    "    - **Zoneout**: LSTM에서 사용되는 드롭아웃 기반의 정규화 기술\n",
    "    <img src=\"05.png\" width=50% height=50%>\n",
    "    \n",
    "        - $d$를 dropout mask라 할 때, 식은 다음과 같다.\n",
    "        <img src=\"06.png\" width=70% height=70%>\n",
    "        \n",
    "        - NVIDIA는 Zoneout을 코드로 구현하지 않았다. (추가가 가능하다고 언급함.)\n",
    "        \n",
    "    - **Stop Token**: 추론 단계에서 Mel-Spectrogram의 생성을 멈출지 결정하는 역할을 하는 Token\n",
    "        - Stop Token은 sigmoid 활성화 함수를 통과하여 0에서 1 사이의 값을 갖고, **threshold**(보통 0.5)를 넘으면 생성을 멈추도록 한다.\n",
    "    - **Teacher Forcing**: 학습 시 Ground-truth Mel-Spectrogram이 Decoder의 input으로 들어간다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b162a530",
   "metadata": {},
   "source": [
    "## 4. WaveNet Vocoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec2aab2",
   "metadata": {},
   "source": [
    "- 먼저 PixelCNN++ 논문에서 제시된 **Mixture of logistic distribution(MoL)**를 알아보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a000e56",
   "metadata": {},
   "source": [
    "## 4.1. Mixture of Logistic Distribution(MoL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181a1cdf",
   "metadata": {},
   "source": [
    "- **Discretized Logistic Mixture Likelihood**: Mixture of logistic distribution을 이용한 이산 데이터를 예측하는 기법\n",
    "    - **Mixture of logistic distribution**: 로지스틱 분포의 혼합, **로지스틱 분포**는 로지스틱 함수를 누적분포함수로 갖는 분포이다.\n",
    "        - 로지스틱 함수의 식과 그림은 다음과 같다. (시그모이드 함수는 로지스틱 함수의 일종이다.)\n",
    "        $$ F(x; \\mu, s) = \\frac{1}{1 + e^{-(x-\\mu)/s}}$$\n",
    "        <img src=\"07.png\" width=30% height=30%>\n",
    "        \n",
    "        - 로지스틱 분포의 식과 그림은 다음과 같다.\n",
    "        $$ f(x; \\mu, s) = \\frac{e^{-(x-\\mu)/s}}{s(1 + e^{-(x-\\mu)/s})^{2}}$$\n",
    "        <img src=\"08.png\" width=30% height=30%>\n",
    "        \n",
    "    - 그림을 생성할 때 Pixel의 색상마다 256개(0~256)의 정수를 예측하게 된다.\n",
    "    - 이때 Softmax 함수를 이용하여 해당 픽셀을 128이라 예측한다면, 이 모델은 이 값이 127과 129에 가깝다는 것을 모른다.  \n",
    "    (그 관계를 학습하지 않았기 때문이다.)\n",
    "        - 예를 들어, Softmax를 통과한 확률 분포가 [0.05, ..., **0**, **0.9**, **0**, ..., 0.05]와 같이 나타날 수 있다.\n",
    "        \n",
    "    - 이 문제를 해결하기 위해 Pixel 색상의 256개의 정수가 어떤 연속함수의 확률분포를 형성한다고 가정한다.\n",
    "        - 이때 이 연속함수를 **로지스틱의 분포의 혼합**으로 둔다.\n",
    "        <img src=\"09.png\" width=50% height=50%>\n",
    "        ($\\nu$: Pixel 색상의 확률 분포, $\\mu$: 모수, 평균(mean), $s$: 모수, 로그 스케일(scale), $\\pi$: 모수, 혼합 가중치(mixture weight), $x$: Pixel의 정수 값, $K$: 로지스틱 분포 혼합 개수)\n",
    "        \n",
    "    - 이 모수들을 학습하면, 1) 연속적인 분포를 학습할 수 있고, 2) $K=5$로도 충분하여 학습할 파라미터 수($K=5$인 경우 15개)도 적어진다.\n",
    "    - **loss**는 **Negative Log-Likelihood**를 이용한다.\n",
    "    \n",
    "    - 실제 CIFAR-10 데이터의 픽셀의 색상(sub-pixel)값 분포는 다음과 같다. (이 분포를 학습하고자 하는 것이다.)\n",
    "    <img src=\"10.png\" width=50% height=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdce89e",
   "metadata": {},
   "source": [
    "## 4.2. WaveNet Vocoder Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0c3cb8",
   "metadata": {},
   "source": [
    "- **WaveNet Vocoder 전체 구조**\n",
    "<img src=\"11.png\" width=70% height=70%>\n",
    "\n",
    "    - **Input**: Ground truth의 waveform (추론할 때에는 output의 waveform)\n",
    "    - **Local Condition**: Tacotron2로부터 생성한 mel-spectrogram\n",
    "    - **Global Condition**: 화자의 정보 (예: 문재인 대통령은 0, 손석희 아나운서는 1, ...)\n",
    "    - **MoL Functions**: <u>10개의 MoL</u>을 이용하여 학습하도록 한다. 이로부터 양자화($-2^{15} \\sim 2^{15}-1$)된 waveform을 예측한다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8594a488",
   "metadata": {},
   "source": [
    "**[참고 논문]**\n",
    "1. Tacotron2: https://arxiv.org/abs/1712.05884v2\n",
    "2. Zoneout: https://arxiv.org/abs/1606.01305v4\n",
    "3. PixelCNN++: https://arxiv.org/abs/1701.05517"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c137ae9",
   "metadata": {},
   "source": [
    "**[참고 자료 / 사진 출처]**\n",
    "1. Tacotron2 리뷰1: https://joungheekim.github.io/2020/10/08/paper-review/\n",
    "2. Tacotron2 리뷰2: https://chldkato.tistory.com/176\n",
    "3. Tacotron2 Github (NVIDIA): https://github.com/NVIDIA/tacotron2/tree/fc0cf6a89a47166350b65daa1beaa06979e4cddf\n",
    "4. Location-Sensitive Attention: https://paperswithcode.com/method/location-sensitive-attention\n",
    "5. Zoneout: https://paperswithcode.com/method/zoneout\n",
    "6. NVIDIA가 구현한 코드에는 Zoneout이 없음: https://github.com/NVIDIA/tacotron2/issues/13\n",
    "7. NVIDIA Issue: https://github.com/NVIDIA/tacotron2/issues/25\n",
    "8. Tacotron2 Github (hccho2): https://github.com/hccho2/Tacotron2-Wavenet-Korean-TTS\n",
    "9. Tacotron2 Github (Rayhane-mamah): https://github.com/Rayhane-mamah/Tacotron-2\n",
    "10. Wikipedia, Logistic function: https://en.wikipedia.org/wiki/Logistic_function\n",
    "11. Wikipedia, Logistic distribution: https://en.wikipedia.org/wiki/Logistic_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73572f2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
